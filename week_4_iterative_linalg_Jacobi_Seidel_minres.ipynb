{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.22044605e-16])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3679761958864619, array([1.16942618e-04, 8.46670912e-05, 8.84444342e-05, 9.06403170e-05,\n",
      "       1.39709460e-04, 1.53519592e-04, 1.28330222e-04, 9.84880665e-05,\n",
      "       9.82795627e-05, 1.31681085e-04]))\n",
      "(0.3679761958864619, array([6.57111102e-10, 4.75752215e-10, 4.96977015e-10, 5.09316145e-10,\n",
      "       7.85040144e-10, 8.62640515e-10, 7.21099291e-10, 5.53413426e-10,\n",
      "       5.52241808e-10, 7.39928230e-10]))\n",
      "\n",
      "(0.6907921005349461, array([1.34296197e-04, 1.73432087e-04, 9.49049918e-05, 1.73278057e-04,\n",
      "       1.98050855e-04, 1.38879957e-04, 1.37158007e-04, 1.80803730e-04,\n",
      "       1.49862491e-04, 1.30893980e-04]))\n",
      "(0.6907921005349461, array([1.77567061e-09, 2.29312702e-09, 1.25483823e-09, 2.29109054e-09,\n",
      "       2.61863764e-09, 1.83627727e-09, 1.81350968e-09, 2.39059533e-09,\n",
      "       1.98148883e-09, 1.73068631e-09]))\n",
      "\n",
      "(1.116708536930544, array([0.19156323, 0.17471991, 0.2106979 , 0.18306477, 0.17234526,\n",
      "       0.17636312, 0.17758376, 0.17349296, 0.21549215, 0.20986031]))\n",
      "(1.116708536930544, array([0.00691134, 0.00630366, 0.0076017 , 0.00660473, 0.00621798,\n",
      "       0.00636294, 0.00640698, 0.00625939, 0.00777467, 0.00757148]))\n",
      "\n",
      "(2.0860550510658484, array([4.07914890e+09, 5.79404724e+09, 4.31101175e+09, 3.60950019e+09,\n",
      "       4.88624697e+09, 4.83877414e+09, 5.05574444e+09, 3.02865794e+09,\n",
      "       5.82176493e+09, 5.32510612e+09]))\n",
      "(2.0860550510658484, array([2.97889002e+18, 4.23123302e+18, 3.14821307e+18, 2.63591851e+18,\n",
      "       3.56829149e+18, 3.53362340e+18, 3.69207083e+18, 2.21174543e+18,\n",
      "       4.25147448e+18, 3.88877824e+18]))\n"
     ]
    }
   ],
   "source": [
    "def Jacobi_iteration(A, b, n_iter):\n",
    "    diag_1d = np.diag(A)\n",
    "\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "\n",
    "    D = np.diag(diag_1d)\n",
    "    invD = np.diag(1./diag_1d)\n",
    "    BB = invD @ B \n",
    "    c = invD @ b\n",
    "    \n",
    "    x = np.ones(n)\n",
    "    for _ in range(n_iter):\n",
    "        x = BB @ x + c\n",
    "        \n",
    "    \"\"\"Возвращает:\n",
    "    ||B|| - норму матрицы B\n",
    "     Δb   - разницу между A @ x и вектором b \n",
    "    \"\"\"\n",
    "    \n",
    "    return np.linalg.norm(BB), A @ x-b\n",
    "\n",
    "\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Jacobi_iteration(A, b, 10))\n",
    "print(Jacobi_iteration(A, b, 20))\n",
    "print()\n",
    "\n",
    "# Cделаем диагональные элементы в два раза меньше\n",
    "# - для той же точности потребуется в два раза больше повторений\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([7]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Jacobi_iteration(A, b, 20))\n",
    "print(Jacobi_iteration(A, b, 40))\n",
    "print()\n",
    "\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([5]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Jacobi_iteration(A, b, 60))\n",
    "print(Jacobi_iteration(A, b, 110))\n",
    "print()\n",
    "\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([2]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "# Если уменьшать диагональные момены, в определённый момент норма матрицы B станет больше 1\n",
    "# \n",
    "print(Jacobi_iteration(A, b, 40))\n",
    "print(Jacobi_iteration(A, b, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seidel`s iteration description\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part D, upper trianglular and lower triangular parts U and L,\n",
    "\n",
    "$$ A = L + U + D $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = - (D + L)^{-1} U x + (D + L)^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "D x_{n + 1} + L x_{n + 1} + U x_{n} = b\\;,\n",
    "$$\n",
    "\n",
    "Matrix of iterations is\n",
    "\n",
    "$$\n",
    "M = - (D + L)^{-1} U\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Seidels_iteration(A, b, n_iter):\n",
    "    n = A.shape[0]\n",
    "    diag_1d = np.diag(A)\n",
    "\n",
    "    D = np.diag(diag_1d)\n",
    "    L = np.eye(n)\n",
    "    U = np.eye(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n-i):\n",
    "            U[i,j+i] = A[i,j+i].copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            L[i,j] = A[i,j].copy()\n",
    "    \n",
    "    np.fill_diagonal(L, 0)\n",
    "    np.fill_diagonal(U, 0)\n",
    "    \n",
    "    # Show matrices D, U and L\n",
    "    # print((D*1e5)//1e2/1e3)\n",
    "    # print((U*1e5)//1e2/1e3)\n",
    "    # print((L*1e5)//1e2/1e3)\n",
    "    \n",
    "    x = np.ones(n)\n",
    "    x1 = np.zeros(n)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        for k in range(n):\n",
    "            x1[k] = (b[k] - np.dot(L[k,::], x1) - np.dot(U[k,::], x))/D[k,k]\n",
    "        x = x1\n",
    "        \n",
    "        # Следим за последним элементом\n",
    "        # print(x1[n-1])\n",
    "        \n",
    "    M = - np.linalg.inv(L+D) @ U\n",
    "\n",
    "    \"\"\"Возвращает:\n",
    "    ||M|| - норму матрицы M\n",
    "     Δb   - разницу между A @ x и вектором b \n",
    "    \"\"\"\n",
    "    return np.linalg.norm(M), A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Series of tests\n",
    "\n",
    "There is displayed observing of how diagonal elements value influences convergence of method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2112162315549301, array([3.26338956e-12, 9.90985072e-13, 6.89159840e-12, 4.58244553e-12,\n",
      "       4.97279995e-12, 1.77421966e-12, 3.36297656e-12, 7.41018358e-13,\n",
      "       2.16604512e-13, 0.00000000e+00]))\n",
      "(0.2112162315549301, array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.11022302e-16,\n",
      "        0.00000000e+00, -6.93889390e-18,  0.00000000e+00, -5.55111512e-17,\n",
      "        1.11022302e-16,  0.00000000e+00]))\n",
      "\n",
      "(0.46508122481184316, array([ 1.52851166e-08,  3.75978430e-08,  5.17386667e-08,  2.64267643e-08,\n",
      "        2.43330129e-08,  3.29431338e-09,  4.03871903e-09, -1.97347527e-09,\n",
      "       -4.52838572e-10,  0.00000000e+00]))\n",
      "(0.46508122481184316, array([ 1.11022302e-16,  2.77555756e-17,  0.00000000e+00,  0.00000000e+00,\n",
      "       -1.11022302e-16, -5.55111512e-17,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00]))\n",
      "\n",
      "(0.7137184917231388, array([-2.34393357e-07, -1.54717067e-07, -2.26365476e-07, -2.32619961e-07,\n",
      "       -2.40343595e-07, -3.96763414e-08, -1.26255371e-07, -1.88608251e-08,\n",
      "        8.88114948e-09,  0.00000000e+00]))\n",
      "(0.7137184917231388, array([ 5.23192600e-15,  6.43929354e-15, -4.44089210e-16,  3.16413562e-15,\n",
      "       -1.66533454e-15, -8.88178420e-16, -3.71924713e-15, -2.55351296e-15,\n",
      "       -7.77156117e-16,  0.00000000e+00]))\n",
      "\n",
      "(4.317934008433141, array([ 6.42279449e-01,  7.93776790e+00,  6.74861917e-01, -1.92438960e+00,\n",
      "       -6.71186776e+00, -8.28303125e-01,  1.14846369e+01, -9.85766255e+00,\n",
      "        1.89688367e+00,  4.10782519e-15]))\n",
      "(4.317934008433141, array([-1.69924743e+01,  6.28076327e-01,  1.82571972e+01, -1.53115734e+01,\n",
      "       -2.44682752e+01, -1.44282697e+01,  6.39584055e+00, -2.95411347e+01,\n",
      "       -2.04210905e+00,  6.09512441e-14]))\n"
     ]
    }
   ],
   "source": [
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Seidels_iteration(A, b, 10))\n",
    "print(Seidels_iteration(A, b, 20))\n",
    "print()\n",
    "\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([7]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Seidels_iteration(A, b, 10))\n",
    "print(Seidels_iteration(A, b, 20))\n",
    "print()\n",
    "\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([4]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Seidels_iteration(A, b, 10))\n",
    "print(Seidels_iteration(A, b, 20))\n",
    "print()\n",
    "\n",
    "# Перестаёт сходиться\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat(n)\n",
    "b = rndm.uniform(size=n)\n",
    "\n",
    "print(Seidels_iteration(A, b, 10))\n",
    "print(Seidels_iteration(A, b, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
